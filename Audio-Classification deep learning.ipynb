{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29ce9c15",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\avisi\\anaconda3\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from librosa) (1.0.1)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: resampy>=0.2.2 in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from librosa) (1.20.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from librosa) (20.9)\n",
      "Requirement already satisfied: audioread>=2.0.0 in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from librosa) (2.1.9)\n",
      "Requirement already satisfied: numba>=0.43.0 in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from librosa) (0.53.1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from librosa) (0.24.1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from librosa) (5.0.6)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from librosa) (1.4.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from numba>=0.43.0->librosa) (52.0.0.post20210125)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from numba>=0.43.0->librosa) (0.36.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from packaging>=20.0->librosa) (2.4.7)\n",
      "Requirement already satisfied: appdirs in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: requests in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (2.25.1)\n",
      "Requirement already satisfied: six>=1.3 in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (2.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from soundfile>=0.10.2->librosa) (1.14.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.20)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\avisi\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "# librosa is a python package for music and audio analysis. It provides the building blocks necessary to create\n",
    "# music information retrieval systems.\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5113798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.5</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.5</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.0</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.5</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
       "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
       "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
       "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
       "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
       "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
       "\n",
       "              class  \n",
       "0          dog_bark  \n",
       "1  children_playing  \n",
       "2  children_playing  \n",
       "3  children_playing  \n",
       "4  children_playing  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Extracting MFCC's For every audio file\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "audio_dataset_path='UrbanSound8K/audio/'\n",
    "metadata=pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "710a7e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "street_music        1000\n",
       "children_playing    1000\n",
       "engine_idling       1000\n",
       "jackhammer          1000\n",
       "dog_bark            1000\n",
       "air_conditioner     1000\n",
       "drilling            1000\n",
       "siren                929\n",
       "car_horn             429\n",
       "gun_shot             374\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check whether the dataset is imbalanced or not\n",
    "metadata['class'].value_counts()\n",
    "# the data is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52a8e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') # get audio and sample rate\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40) # give audio and sample rate to mfcc\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0) # doing transpose of mfccs_features\n",
    "    #np.mean is use to get the scale data\n",
    "\n",
    "    return mfccs_scaled_features\n",
    "# this is used to extract a single audio file for multiple we use loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c1c6ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3555it [08:02,  7.17it/s]C:\\Users\\avisi\\anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
      "  warnings.warn(\n",
      "8324it [18:04, 11.80it/s]C:\\Users\\avisi\\anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
      "  warnings.warn(\n",
      "8327it [18:04, 15.02it/s]C:\\Users\\avisi\\anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
      "  warnings.warn(\n",
      "8732it [18:40,  7.79it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "### tqdm is a library in Python which is used for creating Progress Meters or Progress Bars. tqdm got its name from the\n",
    "### Arabic name taqaddum which means ‘progress’.It will show you the progress meter below when u run it.\n",
    "### Now we iterate through every audio file and extract features \n",
    "### using Mel-Frequency Cepstral Coefficients\n",
    "extracted_features=[]\n",
    "for index_num,row in tqdm(metadata.iterrows()):# use iterrows to extract all the rows\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))# get the file name\n",
    "    final_class_labels=row[\"class\"]\n",
    "    data=features_extractor(file_name)\n",
    "    extracted_features.append([data,final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e185f168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-215.79301, 71.66612, -131.81377, -52.09133, ...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-424.68677, 110.56227, -54.148235, 62.01074, ...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-459.56467, 122.800354, -47.92471, 53.265697,...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-414.55377, 102.896904, -36.66495, 54.18041, ...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-447.397, 115.0954, -53.809113, 61.60859, 1.6...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature             class\n",
       "0  [-215.79301, 71.66612, -131.81377, -52.09133, ...          dog_bark\n",
       "1  [-424.68677, 110.56227, -54.148235, 62.01074, ...  children_playing\n",
       "2  [-459.56467, 122.800354, -47.92471, 53.265697,...  children_playing\n",
       "3  [-414.55377, 102.896904, -36.66495, 54.18041, ...  children_playing\n",
       "4  [-447.397, 115.0954, -53.809113, 61.60859, 1.6...  children_playing"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### converting extracted_features to Pandas dataframe\n",
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f22ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the dataset into independent and dependent dataset\n",
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91d40d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 40)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "082eac9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dog_bark', 'children_playing', 'children_playing', ...,\n",
       "       'car_horn', 'car_horn', 'car_horn'], dtype='<U16')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b587126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))# convert y classes into 0,1,2,3 to 9 becoz there are total 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "364d0acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1df5e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bee5de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54984b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3183614e+02,  1.1397464e+02, -2.3956861e+01, ...,\n",
       "         3.3314774e+00, -1.4786110e+00,  2.8736601e+00],\n",
       "       [-1.4074220e+01,  9.1916939e+01, -8.6787214e+00, ...,\n",
       "        -3.3844023e+00, -5.2119045e+00, -1.5936139e+00],\n",
       "       [-4.9532028e+01,  1.5521857e-01, -2.0369110e+01, ...,\n",
       "         2.0491767e+00, -8.0537474e-01,  2.7793028e+00],\n",
       "       ...,\n",
       "       [-4.2699332e+02,  9.2890656e+01,  3.0233388e+00, ...,\n",
       "         8.6335957e-01,  6.4766806e-01,  7.8490508e-01],\n",
       "       [-1.4607024e+02,  1.3709459e+02, -3.4298344e+01, ...,\n",
       "         1.3777871e+00, -1.9530845e+00, -8.9652127e-01],\n",
       "       [-4.2167450e+02,  2.1169032e+02,  2.6820304e+00, ...,\n",
       "        -5.1484952e+00, -3.6400862e+00, -1.3321609e+00]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b05af86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6985, 40)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15f29bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1747, 40)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db1d7ab",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f42de70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1716692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aedab97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### No of classes\n",
    "### for getting the no. of classes\n",
    "num_labels=y.shape[1]\n",
    "num_labels\n",
    "# we have 10 classes or output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0af6822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(40,)))# because in training data we have 40 features\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50a6ba95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               4100      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 45,410\n",
      "Trainable params: 45,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8267f84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef669523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "216/219 [============================>.] - ETA: 0s - loss: 11.8072 - accuracy: 0.1253\n",
      "Epoch 00001: val_loss improved from inf to 2.29048, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 11.7159 - accuracy: 0.1250 - val_loss: 2.2905 - val_accuracy: 0.1139\n",
      "Epoch 2/200\n",
      "194/219 [=========================>....] - ETA: 0s - loss: 2.6408 - accuracy: 0.1192\n",
      "Epoch 00002: val_loss improved from 2.29048 to 2.28175, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 2.6123 - accuracy: 0.1203 - val_loss: 2.2818 - val_accuracy: 0.1110\n",
      "Epoch 3/200\n",
      "195/219 [=========================>....] - ETA: 0s - loss: 2.3531 - accuracy: 0.1242\n",
      "Epoch 00003: val_loss improved from 2.28175 to 2.26719, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 2.3485 - accuracy: 0.1234 - val_loss: 2.2672 - val_accuracy: 0.1179\n",
      "Epoch 4/200\n",
      "215/219 [============================>.] - ETA: 0s - loss: 2.2695 - accuracy: 0.1227\n",
      "Epoch 00004: val_loss improved from 2.26719 to 2.20206, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.2681 - accuracy: 0.1224 - val_loss: 2.2021 - val_accuracy: 0.1597\n",
      "Epoch 5/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 2.2316 - accuracy: 0.1612\n",
      "Epoch 00005: val_loss improved from 2.20206 to 2.14162, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.2315 - accuracy: 0.1595 - val_loss: 2.1416 - val_accuracy: 0.1769\n",
      "Epoch 6/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 2.1887 - accuracy: 0.1756\n",
      "Epoch 00006: val_loss improved from 2.14162 to 2.11990, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.1905 - accuracy: 0.1745 - val_loss: 2.1199 - val_accuracy: 0.2129\n",
      "Epoch 7/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 2.1563 - accuracy: 0.1909\n",
      "Epoch 00007: val_loss improved from 2.11990 to 2.01588, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.1560 - accuracy: 0.1908 - val_loss: 2.0159 - val_accuracy: 0.2541\n",
      "Epoch 8/200\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 2.0907 - accuracy: 0.2100\n",
      "Epoch 00008: val_loss improved from 2.01588 to 1.97850, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.0920 - accuracy: 0.2096 - val_loss: 1.9785 - val_accuracy: 0.2667\n",
      "Epoch 9/200\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 2.0706 - accuracy: 0.2213\n",
      "Epoch 00009: val_loss improved from 1.97850 to 1.93147, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.0728 - accuracy: 0.2205 - val_loss: 1.9315 - val_accuracy: 0.2788\n",
      "Epoch 10/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 2.0367 - accuracy: 0.2383\n",
      "Epoch 00010: val_loss improved from 1.93147 to 1.91658, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.0367 - accuracy: 0.2389 - val_loss: 1.9166 - val_accuracy: 0.2936\n",
      "Epoch 11/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 2.0024 - accuracy: 0.2522\n",
      "Epoch 00011: val_loss improved from 1.91658 to 1.87226, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 2.0025 - accuracy: 0.2518 - val_loss: 1.8723 - val_accuracy: 0.3205\n",
      "Epoch 12/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 1.9570 - accuracy: 0.2693\n",
      "Epoch 00012: val_loss improved from 1.87226 to 1.82458, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.9581 - accuracy: 0.2679 - val_loss: 1.8246 - val_accuracy: 0.3429\n",
      "Epoch 13/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 1.9364 - accuracy: 0.2914\n",
      "Epoch 00013: val_loss improved from 1.82458 to 1.75999, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.9347 - accuracy: 0.2928 - val_loss: 1.7600 - val_accuracy: 0.3835\n",
      "Epoch 14/200\n",
      "204/219 [==========================>...] - ETA: 0s - loss: 1.8823 - accuracy: 0.3133\n",
      "Epoch 00014: val_loss improved from 1.75999 to 1.68892, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.8782 - accuracy: 0.3144 - val_loss: 1.6889 - val_accuracy: 0.4127\n",
      "Epoch 15/200\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 1.8408 - accuracy: 0.3252\n",
      "Epoch 00015: val_loss improved from 1.68892 to 1.65320, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.8358 - accuracy: 0.3267 - val_loss: 1.6532 - val_accuracy: 0.4098\n",
      "Epoch 16/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.7882 - accuracy: 0.3433\n",
      "Epoch 00016: val_loss improved from 1.65320 to 1.59621, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.7884 - accuracy: 0.3435 - val_loss: 1.5962 - val_accuracy: 0.4539\n",
      "Epoch 17/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 1.7329 - accuracy: 0.3720 ETA: 0s - loss: 1.7460 - accuracy\n",
      "Epoch 00017: val_loss improved from 1.59621 to 1.53166, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.7298 - accuracy: 0.3719 - val_loss: 1.5317 - val_accuracy: 0.4888\n",
      "Epoch 18/200\n",
      "202/219 [==========================>...] - ETA: 0s - loss: 1.7150 - accuracy: 0.3827\n",
      "Epoch 00018: val_loss improved from 1.53166 to 1.51451, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.7112 - accuracy: 0.3851 - val_loss: 1.5145 - val_accuracy: 0.4963\n",
      "Epoch 19/200\n",
      "202/219 [==========================>...] - ETA: 0s - loss: 1.6628 - accuracy: 0.4049\n",
      "Epoch 00019: val_loss improved from 1.51451 to 1.46717, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.6588 - accuracy: 0.4073 - val_loss: 1.4672 - val_accuracy: 0.5003\n",
      "Epoch 20/200\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 1.6210 - accuracy: 0.4209\n",
      "Epoch 00020: val_loss improved from 1.46717 to 1.43195, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.6225 - accuracy: 0.4216 - val_loss: 1.4319 - val_accuracy: 0.5117\n",
      "Epoch 21/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.5914 - accuracy: 0.4283\n",
      "Epoch 00021: val_loss improved from 1.43195 to 1.40149, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.5938 - accuracy: 0.4279 - val_loss: 1.4015 - val_accuracy: 0.5232\n",
      "Epoch 22/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 1.5770 - accuracy: 0.4445\n",
      "Epoch 00022: val_loss improved from 1.40149 to 1.38112, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.5741 - accuracy: 0.4458 - val_loss: 1.3811 - val_accuracy: 0.5369\n",
      "Epoch 23/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 1.5418 - accuracy: 0.4659\n",
      "Epoch 00023: val_loss improved from 1.38112 to 1.35329, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.5414 - accuracy: 0.4661 - val_loss: 1.3533 - val_accuracy: 0.5421\n",
      "Epoch 24/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 1.5170 - accuracy: 0.4647\n",
      "Epoch 00024: val_loss improved from 1.35329 to 1.32004, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.5150 - accuracy: 0.4651 - val_loss: 1.3200 - val_accuracy: 0.5758\n",
      "Epoch 25/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/219 [===========================>..] - ETA: 0s - loss: 1.4991 - accuracy: 0.4751\n",
      "Epoch 00025: val_loss improved from 1.32004 to 1.29171, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.5007 - accuracy: 0.4754 - val_loss: 1.2917 - val_accuracy: 0.5736\n",
      "Epoch 26/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 1.4565 - accuracy: 0.4903\n",
      "Epoch 00026: val_loss improved from 1.29171 to 1.26222, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.4568 - accuracy: 0.4915 - val_loss: 1.2622 - val_accuracy: 0.5947\n",
      "Epoch 27/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 1.4353 - accuracy: 0.4978\n",
      "Epoch 00027: val_loss improved from 1.26222 to 1.25887, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.4368 - accuracy: 0.4974 - val_loss: 1.2589 - val_accuracy: 0.5804\n",
      "Epoch 28/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 1.4187 - accuracy: 0.5049 ETA: 0s - loss: 1.3924 - ac\n",
      "Epoch 00028: val_loss improved from 1.25887 to 1.21282, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.4159 - accuracy: 0.5058 - val_loss: 1.2128 - val_accuracy: 0.6131\n",
      "Epoch 29/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 1.3988 - accuracy: 0.5161\n",
      "Epoch 00029: val_loss did not improve from 1.21282\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.3986 - accuracy: 0.5160 - val_loss: 1.2368 - val_accuracy: 0.5930\n",
      "Epoch 30/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.3893 - accuracy: 0.5212\n",
      "Epoch 00030: val_loss did not improve from 1.21282\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.3900 - accuracy: 0.5211 - val_loss: 1.2133 - val_accuracy: 0.5987\n",
      "Epoch 31/200\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 1.3587 - accuracy: 0.5318\n",
      "Epoch 00031: val_loss improved from 1.21282 to 1.17976, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.3566 - accuracy: 0.5323 - val_loss: 1.1798 - val_accuracy: 0.6159\n",
      "Epoch 32/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 1.3616 - accuracy: 0.5330\n",
      "Epoch 00032: val_loss improved from 1.17976 to 1.16122, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.3600 - accuracy: 0.5341 - val_loss: 1.1612 - val_accuracy: 0.6102\n",
      "Epoch 33/200\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 1.3342 - accuracy: 0.5419\n",
      "Epoch 00033: val_loss improved from 1.16122 to 1.12648, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.3335 - accuracy: 0.5424 - val_loss: 1.1265 - val_accuracy: 0.6297\n",
      "Epoch 34/200\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 1.3239 - accuracy: 0.5460\n",
      "Epoch 00034: val_loss did not improve from 1.12648\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.3215 - accuracy: 0.5477 - val_loss: 1.1500 - val_accuracy: 0.6262\n",
      "Epoch 35/200\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 1.3013 - accuracy: 0.5560\n",
      "Epoch 00035: val_loss improved from 1.12648 to 1.10487, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.2983 - accuracy: 0.5558 - val_loss: 1.1049 - val_accuracy: 0.6400\n",
      "Epoch 36/200\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 1.2922 - accuracy: 0.5533\n",
      "Epoch 00036: val_loss improved from 1.10487 to 1.10226, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.3018 - accuracy: 0.5528 - val_loss: 1.1023 - val_accuracy: 0.6457\n",
      "Epoch 37/200\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 1.2652 - accuracy: 0.5637\n",
      "Epoch 00037: val_loss improved from 1.10226 to 1.09507, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.2623 - accuracy: 0.5636 - val_loss: 1.0951 - val_accuracy: 0.6308\n",
      "Epoch 38/200\n",
      "204/219 [==========================>...] - ETA: 0s - loss: 1.2603 - accuracy: 0.5685\n",
      "Epoch 00038: val_loss improved from 1.09507 to 1.07157, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.2609 - accuracy: 0.5696 - val_loss: 1.0716 - val_accuracy: 0.6640\n",
      "Epoch 39/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 1.2606 - accuracy: 0.5697\n",
      "Epoch 00039: val_loss did not improve from 1.07157\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.2617 - accuracy: 0.5702 - val_loss: 1.0722 - val_accuracy: 0.6503\n",
      "Epoch 40/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.2602 - accuracy: 0.5740\n",
      "Epoch 00040: val_loss improved from 1.07157 to 1.06433, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.2611 - accuracy: 0.5739 - val_loss: 1.0643 - val_accuracy: 0.6480\n",
      "Epoch 41/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 1.2411 - accuracy: 0.5722\n",
      "Epoch 00041: val_loss improved from 1.06433 to 1.02090, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.2415 - accuracy: 0.5709 - val_loss: 1.0209 - val_accuracy: 0.6857\n",
      "Epoch 42/200\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 1.2210 - accuracy: 0.5810\n",
      "Epoch 00042: val_loss did not improve from 1.02090\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.2221 - accuracy: 0.5818 - val_loss: 1.0443 - val_accuracy: 0.6669\n",
      "Epoch 43/200\n",
      "219/219 [==============================] - ETA: 0s - loss: 1.2177 - accuracy: 0.5877\n",
      "Epoch 00043: val_loss improved from 1.02090 to 1.01959, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.2177 - accuracy: 0.5877 - val_loss: 1.0196 - val_accuracy: 0.6766\n",
      "Epoch 44/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 1.2143 - accuracy: 0.5861\n",
      "Epoch 00044: val_loss did not improve from 1.01959\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.2142 - accuracy: 0.5865 - val_loss: 1.0323 - val_accuracy: 0.6669\n",
      "Epoch 45/200\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 1.1931 - accuracy: 0.5916\n",
      "Epoch 00045: val_loss did not improve from 1.01959\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1955 - accuracy: 0.5895 - val_loss: 1.0513 - val_accuracy: 0.6629\n",
      "Epoch 46/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.1992 - accuracy: 0.5942\n",
      "Epoch 00046: val_loss did not improve from 1.01959\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1980 - accuracy: 0.5943 - val_loss: 1.0509 - val_accuracy: 0.6611\n",
      "Epoch 47/200\n",
      "216/219 [============================>.] - ETA: 0s - loss: 1.1994 - accuracy: 0.5935\n",
      "Epoch 00047: val_loss improved from 1.01959 to 1.00289, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1969 - accuracy: 0.5941 - val_loss: 1.0029 - val_accuracy: 0.6783\n",
      "Epoch 48/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 1.1562 - accuracy: 0.6105\n",
      "Epoch 00048: val_loss improved from 1.00289 to 0.97234, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1595 - accuracy: 0.6084 - val_loss: 0.9723 - val_accuracy: 0.6749\n",
      "Epoch 49/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 1.1809 - accuracy: 0.6028\n",
      "Epoch 00049: val_loss did not improve from 0.97234\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 1.1841 - accuracy: 0.6019 - val_loss: 1.0176 - val_accuracy: 0.6674\n",
      "Epoch 50/200\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 1.1496 - accuracy: 0.6110\n",
      "Epoch 00050: val_loss improved from 0.97234 to 0.94591, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1446 - accuracy: 0.6135 - val_loss: 0.9459 - val_accuracy: 0.6943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 1.1556 - accuracy: 0.6013\n",
      "Epoch 00051: val_loss did not improve from 0.94591\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1569 - accuracy: 0.6007 - val_loss: 0.9547 - val_accuracy: 0.6961\n",
      "Epoch 52/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.1553 - accuracy: 0.6069\n",
      "Epoch 00052: val_loss did not improve from 0.94591\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1550 - accuracy: 0.6072 - val_loss: 0.9547 - val_accuracy: 0.6886\n",
      "Epoch 53/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 1.1254 - accuracy: 0.6224\n",
      "Epoch 00053: val_loss improved from 0.94591 to 0.94549, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1257 - accuracy: 0.6222 - val_loss: 0.9455 - val_accuracy: 0.6949\n",
      "Epoch 54/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 1.1121 - accuracy: 0.6162\n",
      "Epoch 00054: val_loss did not improve from 0.94549\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1111 - accuracy: 0.6183 - val_loss: 0.9484 - val_accuracy: 0.6978\n",
      "Epoch 55/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 1.1324 - accuracy: 0.6173\n",
      "Epoch 00055: val_loss improved from 0.94549 to 0.93682, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1301 - accuracy: 0.6183 - val_loss: 0.9368 - val_accuracy: 0.7018\n",
      "Epoch 56/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 1.1125 - accuracy: 0.6286\n",
      "Epoch 00056: val_loss improved from 0.93682 to 0.92903, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1124 - accuracy: 0.6288 - val_loss: 0.9290 - val_accuracy: 0.6978\n",
      "Epoch 57/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 1.1292 - accuracy: 0.6180\n",
      "Epoch 00057: val_loss improved from 0.92903 to 0.90582, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1279 - accuracy: 0.6183 - val_loss: 0.9058 - val_accuracy: 0.7132\n",
      "Epoch 58/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 1.1147 - accuracy: 0.6187\n",
      "Epoch 00058: val_loss did not improve from 0.90582\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1191 - accuracy: 0.6190 - val_loss: 0.9140 - val_accuracy: 0.7075\n",
      "Epoch 59/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 1.1039 - accuracy: 0.6249\n",
      "Epoch 00059: val_loss improved from 0.90582 to 0.89305, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.1042 - accuracy: 0.6230 - val_loss: 0.8931 - val_accuracy: 0.7252\n",
      "Epoch 60/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.0707 - accuracy: 0.6407\n",
      "Epoch 00060: val_loss improved from 0.89305 to 0.88185, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0696 - accuracy: 0.6417 - val_loss: 0.8818 - val_accuracy: 0.7098\n",
      "Epoch 61/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 1.0790 - accuracy: 0.6355\n",
      "Epoch 00061: val_loss improved from 0.88185 to 0.88079, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0800 - accuracy: 0.6354 - val_loss: 0.8808 - val_accuracy: 0.7390\n",
      "Epoch 62/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.0945 - accuracy: 0.6336\n",
      "Epoch 00062: val_loss did not improve from 0.88079\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0934 - accuracy: 0.6338 - val_loss: 0.8878 - val_accuracy: 0.7207\n",
      "Epoch 63/200\n",
      "219/219 [==============================] - ETA: 0s - loss: 1.0950 - accuracy: 0.6341\n",
      "Epoch 00063: val_loss did not improve from 0.88079\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0950 - accuracy: 0.6341 - val_loss: 0.8990 - val_accuracy: 0.7207\n",
      "Epoch 64/200\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 1.0785 - accuracy: 0.6367\n",
      "Epoch 00064: val_loss improved from 0.88079 to 0.86886, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0786 - accuracy: 0.6368 - val_loss: 0.8689 - val_accuracy: 0.7264\n",
      "Epoch 65/200\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 1.0925 - accuracy: 0.6280 ETA: 0s - loss: 1.0964 - accuracy: 0.\n",
      "Epoch 00065: val_loss did not improve from 0.86886\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0857 - accuracy: 0.6292 - val_loss: 0.8911 - val_accuracy: 0.7189\n",
      "Epoch 66/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.0661 - accuracy: 0.6403 ETA: 0s - loss: 1.0712 - accuracy: \n",
      "Epoch 00066: val_loss improved from 0.86886 to 0.85472, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0655 - accuracy: 0.6402 - val_loss: 0.8547 - val_accuracy: 0.7258\n",
      "Epoch 67/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.0743 - accuracy: 0.6393\n",
      "Epoch 00067: val_loss did not improve from 0.85472\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0746 - accuracy: 0.6391 - val_loss: 0.8821 - val_accuracy: 0.7310\n",
      "Epoch 68/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.0611 - accuracy: 0.6453\n",
      "Epoch 00068: val_loss did not improve from 0.85472\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0612 - accuracy: 0.6452 - val_loss: 0.8698 - val_accuracy: 0.7218\n",
      "Epoch 69/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 1.0622 - accuracy: 0.6399\n",
      "Epoch 00069: val_loss did not improve from 0.85472\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0607 - accuracy: 0.6395 - val_loss: 0.8985 - val_accuracy: 0.7064\n",
      "Epoch 70/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 1.0620 - accuracy: 0.6337\n",
      "Epoch 00070: val_loss did not improve from 0.85472\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0602 - accuracy: 0.6324 - val_loss: 0.8805 - val_accuracy: 0.7252\n",
      "Epoch 71/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 1.0363 - accuracy: 0.6484\n",
      "Epoch 00071: val_loss did not improve from 0.85472\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0361 - accuracy: 0.6482 - val_loss: 0.8654 - val_accuracy: 0.7327\n",
      "Epoch 72/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.0377 - accuracy: 0.6545\n",
      "Epoch 00072: val_loss improved from 0.85472 to 0.83493, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0381 - accuracy: 0.6543 - val_loss: 0.8349 - val_accuracy: 0.7333\n",
      "Epoch 73/200\n",
      "219/219 [==============================] - ETA: 0s - loss: 1.0495 - accuracy: 0.6495\n",
      "Epoch 00073: val_loss improved from 0.83493 to 0.82863, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0495 - accuracy: 0.6495 - val_loss: 0.8286 - val_accuracy: 0.7407\n",
      "Epoch 74/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 1.0618 - accuracy: 0.6404\n",
      "Epoch 00074: val_loss did not improve from 0.82863\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0579 - accuracy: 0.6424 - val_loss: 0.8686 - val_accuracy: 0.7178\n",
      "Epoch 75/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.0301 - accuracy: 0.6560\n",
      "Epoch 00075: val_loss did not improve from 0.82863\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0324 - accuracy: 0.6560 - val_loss: 0.8362 - val_accuracy: 0.7441\n",
      "Epoch 76/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 1.0474 - accuracy: 0.6515\n",
      "Epoch 00076: val_loss did not improve from 0.82863\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0466 - accuracy: 0.6518 - val_loss: 0.8485 - val_accuracy: 0.7315\n",
      "Epoch 77/200\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 1.0233 - accuracy: 0.6562\n",
      "Epoch 00077: val_loss did not improve from 0.82863\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0210 - accuracy: 0.6578 - val_loss: 0.8295 - val_accuracy: 0.7355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 1.0417 - accuracy: 0.6591\n",
      "Epoch 00078: val_loss did not improve from 0.82863\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0432 - accuracy: 0.6591 - val_loss: 0.8635 - val_accuracy: 0.7350\n",
      "Epoch 79/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.0271 - accuracy: 0.6586\n",
      "Epoch 00079: val_loss improved from 0.82863 to 0.82008, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0263 - accuracy: 0.6588 - val_loss: 0.8201 - val_accuracy: 0.7470\n",
      "Epoch 80/200\n",
      "216/219 [============================>.] - ETA: 0s - loss: 1.0429 - accuracy: 0.6483\n",
      "Epoch 00080: val_loss did not improve from 0.82008\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0432 - accuracy: 0.6490 - val_loss: 0.8258 - val_accuracy: 0.7499\n",
      "Epoch 81/200\n",
      "202/219 [==========================>...] - ETA: 0s - loss: 1.0258 - accuracy: 0.6564\n",
      "Epoch 00081: val_loss did not improve from 0.82008\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0288 - accuracy: 0.6558 - val_loss: 0.8563 - val_accuracy: 0.7355\n",
      "Epoch 82/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.0210 - accuracy: 0.6550\n",
      "Epoch 00082: val_loss improved from 0.82008 to 0.80375, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0199 - accuracy: 0.6553 - val_loss: 0.8038 - val_accuracy: 0.7464\n",
      "Epoch 83/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 1.0162 - accuracy: 0.6606\n",
      "Epoch 00083: val_loss did not improve from 0.80375\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0165 - accuracy: 0.6606 - val_loss: 0.8046 - val_accuracy: 0.7573\n",
      "Epoch 84/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.0256 - accuracy: 0.6548\n",
      "Epoch 00084: val_loss did not improve from 0.80375\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0262 - accuracy: 0.6545 - val_loss: 0.8277 - val_accuracy: 0.7504\n",
      "Epoch 85/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 1.0149 - accuracy: 0.6561\n",
      "Epoch 00085: val_loss did not improve from 0.80375\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0145 - accuracy: 0.6563 - val_loss: 0.8385 - val_accuracy: 0.7464\n",
      "Epoch 86/200\n",
      "219/219 [==============================] - ETA: 0s - loss: 1.0109 - accuracy: 0.6674\n",
      "Epoch 00086: val_loss did not improve from 0.80375\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0109 - accuracy: 0.6674 - val_loss: 0.8315 - val_accuracy: 0.7562\n",
      "Epoch 87/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 1.0223 - accuracy: 0.6564\n",
      "Epoch 00087: val_loss did not improve from 0.80375\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0221 - accuracy: 0.6563 - val_loss: 0.8289 - val_accuracy: 0.7418\n",
      "Epoch 88/200\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 1.0341 - accuracy: 0.6561\n",
      "Epoch 00088: val_loss did not improve from 0.80375\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0275 - accuracy: 0.6584 - val_loss: 0.8197 - val_accuracy: 0.7481\n",
      "Epoch 89/200\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 1.0033 - accuracy: 0.6629\n",
      "Epoch 00089: val_loss improved from 0.80375 to 0.79590, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9999 - accuracy: 0.6643 - val_loss: 0.7959 - val_accuracy: 0.7550\n",
      "Epoch 90/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9894 - accuracy: 0.6660\n",
      "Epoch 00090: val_loss did not improve from 0.79590\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9940 - accuracy: 0.6650 - val_loss: 0.8288 - val_accuracy: 0.7401\n",
      "Epoch 91/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9954 - accuracy: 0.6673\n",
      "Epoch 00091: val_loss did not improve from 0.79590\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9942 - accuracy: 0.6679 - val_loss: 0.8141 - val_accuracy: 0.7424\n",
      "Epoch 92/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.0088 - accuracy: 0.6691\n",
      "Epoch 00092: val_loss did not improve from 0.79590\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0063 - accuracy: 0.6699 - val_loss: 0.8001 - val_accuracy: 0.7544\n",
      "Epoch 93/200\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 1.0039 - accuracy: 0.6619\n",
      "Epoch 00093: val_loss did not improve from 0.79590\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0034 - accuracy: 0.6611 - val_loss: 0.8036 - val_accuracy: 0.7539\n",
      "Epoch 94/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.9826 - accuracy: 0.6741\n",
      "Epoch 00094: val_loss improved from 0.79590 to 0.77403, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9828 - accuracy: 0.6744 - val_loss: 0.7740 - val_accuracy: 0.7602\n",
      "Epoch 95/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 1.0049 - accuracy: 0.6692\n",
      "Epoch 00095: val_loss did not improve from 0.77403\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0033 - accuracy: 0.6694 - val_loss: 0.8019 - val_accuracy: 0.7613\n",
      "Epoch 96/200\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 0.9891 - accuracy: 0.6632\n",
      "Epoch 00096: val_loss did not improve from 0.77403\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9919 - accuracy: 0.6617 - val_loss: 0.8001 - val_accuracy: 0.7693\n",
      "Epoch 97/200\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.9893 - accuracy: 0.6689\n",
      "Epoch 00097: val_loss did not improve from 0.77403\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9906 - accuracy: 0.6687 - val_loss: 0.8012 - val_accuracy: 0.7470\n",
      "Epoch 98/200\n",
      "212/219 [============================>.] - ETA: 0s - loss: 1.0051 - accuracy: 0.6601\n",
      "Epoch 00098: val_loss did not improve from 0.77403\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 1.0033 - accuracy: 0.6603 - val_loss: 0.7957 - val_accuracy: 0.7567\n",
      "Epoch 99/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9967 - accuracy: 0.6623\n",
      "Epoch 00099: val_loss did not improve from 0.77403\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9966 - accuracy: 0.6624 - val_loss: 0.7801 - val_accuracy: 0.7556\n",
      "Epoch 100/200\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.9712 - accuracy: 0.6753\n",
      "Epoch 00100: val_loss did not improve from 0.77403\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9718 - accuracy: 0.6752 - val_loss: 0.8026 - val_accuracy: 0.7550\n",
      "Epoch 101/200\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.9976 - accuracy: 0.6726\n",
      "Epoch 00101: val_loss did not improve from 0.77403\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9958 - accuracy: 0.6733 - val_loss: 0.7829 - val_accuracy: 0.7596\n",
      "Epoch 102/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.9806 - accuracy: 0.6648\n",
      "Epoch 00102: val_loss did not improve from 0.77403\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9814 - accuracy: 0.6633 - val_loss: 0.8139 - val_accuracy: 0.7533\n",
      "Epoch 103/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.9810 - accuracy: 0.6648\n",
      "Epoch 00103: val_loss did not improve from 0.77403\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9797 - accuracy: 0.6647 - val_loss: 0.7790 - val_accuracy: 0.7636\n",
      "Epoch 104/200\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.9591 - accuracy: 0.6739\n",
      "Epoch 00104: val_loss did not improve from 0.77403\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9591 - accuracy: 0.6739 - val_loss: 0.7878 - val_accuracy: 0.7670\n",
      "Epoch 105/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.9988 - accuracy: 0.6624\n",
      "Epoch 00105: val_loss did not improve from 0.77403\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9975 - accuracy: 0.6630 - val_loss: 0.8013 - val_accuracy: 0.7556\n",
      "Epoch 106/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9763 - accuracy: 0.6653\n",
      "Epoch 00106: val_loss did not improve from 0.77403\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9763 - accuracy: 0.6651 - val_loss: 0.7914 - val_accuracy: 0.7533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.9844 - accuracy: 0.6734\n",
      "Epoch 00107: val_loss did not improve from 0.77403\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9844 - accuracy: 0.6734 - val_loss: 0.7839 - val_accuracy: 0.7544\n",
      "Epoch 108/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9813 - accuracy: 0.6643\n",
      "Epoch 00108: val_loss improved from 0.77403 to 0.76726, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9809 - accuracy: 0.6643 - val_loss: 0.7673 - val_accuracy: 0.7624\n",
      "Epoch 109/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.9864 - accuracy: 0.6714\n",
      "Epoch 00109: val_loss did not improve from 0.76726\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9860 - accuracy: 0.6712 - val_loss: 0.7865 - val_accuracy: 0.7602\n",
      "Epoch 110/200\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.9759 - accuracy: 0.6723 ETA: 0s - loss: 1.014\n",
      "Epoch 00110: val_loss did not improve from 0.76726\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9752 - accuracy: 0.6727 - val_loss: 0.7863 - val_accuracy: 0.7562\n",
      "Epoch 111/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9692 - accuracy: 0.6715\n",
      "Epoch 00111: val_loss did not improve from 0.76726\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9681 - accuracy: 0.6720 - val_loss: 0.7737 - val_accuracy: 0.7539\n",
      "Epoch 112/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.9715 - accuracy: 0.6768\n",
      "Epoch 00112: val_loss did not improve from 0.76726\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9692 - accuracy: 0.6775 - val_loss: 0.7809 - val_accuracy: 0.7550\n",
      "Epoch 113/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9649 - accuracy: 0.6782\n",
      "Epoch 00113: val_loss did not improve from 0.76726\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9644 - accuracy: 0.6783 - val_loss: 0.7785 - val_accuracy: 0.7602\n",
      "Epoch 114/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.9477 - accuracy: 0.6836\n",
      "Epoch 00114: val_loss improved from 0.76726 to 0.75959, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9520 - accuracy: 0.6825 - val_loss: 0.7596 - val_accuracy: 0.7705\n",
      "Epoch 115/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9455 - accuracy: 0.6843\n",
      "Epoch 00115: val_loss did not improve from 0.75959\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9464 - accuracy: 0.6845 - val_loss: 0.7601 - val_accuracy: 0.7584\n",
      "Epoch 116/200\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.9819 - accuracy: 0.6649\n",
      "Epoch 00116: val_loss did not improve from 0.75959\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9819 - accuracy: 0.6649 - val_loss: 0.7728 - val_accuracy: 0.7733\n",
      "Epoch 117/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.9850 - accuracy: 0.6746\n",
      "Epoch 00117: val_loss did not improve from 0.75959\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9872 - accuracy: 0.6744 - val_loss: 0.7797 - val_accuracy: 0.7573\n",
      "Epoch 118/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.9510 - accuracy: 0.6827\n",
      "Epoch 00118: val_loss did not improve from 0.75959\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9516 - accuracy: 0.6822 - val_loss: 0.7654 - val_accuracy: 0.7636\n",
      "Epoch 119/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.9538 - accuracy: 0.6758\n",
      "Epoch 00119: val_loss did not improve from 0.75959\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9538 - accuracy: 0.6772 - val_loss: 0.7641 - val_accuracy: 0.7607\n",
      "Epoch 120/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.9583 - accuracy: 0.6795\n",
      "Epoch 00120: val_loss did not improve from 0.75959\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9575 - accuracy: 0.6803 - val_loss: 0.7778 - val_accuracy: 0.7544\n",
      "Epoch 121/200\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 0.9432 - accuracy: 0.6807\n",
      "Epoch 00121: val_loss did not improve from 0.75959\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9479 - accuracy: 0.6797 - val_loss: 0.7608 - val_accuracy: 0.7710\n",
      "Epoch 122/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9582 - accuracy: 0.6826\n",
      "Epoch 00122: val_loss did not improve from 0.75959\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9579 - accuracy: 0.6826 - val_loss: 0.7754 - val_accuracy: 0.7602\n",
      "Epoch 123/200\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.9709 - accuracy: 0.6759\n",
      "Epoch 00123: val_loss did not improve from 0.75959\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9710 - accuracy: 0.6760 - val_loss: 0.7696 - val_accuracy: 0.7619\n",
      "Epoch 124/200\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.9534 - accuracy: 0.6734\n",
      "Epoch 00124: val_loss improved from 0.75959 to 0.73796, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9534 - accuracy: 0.6734 - val_loss: 0.7380 - val_accuracy: 0.7705\n",
      "Epoch 125/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9410 - accuracy: 0.6876\n",
      "Epoch 00125: val_loss did not improve from 0.73796\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9402 - accuracy: 0.6876 - val_loss: 0.7576 - val_accuracy: 0.7699\n",
      "Epoch 126/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.9520 - accuracy: 0.6806\n",
      "Epoch 00126: val_loss did not improve from 0.73796\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9525 - accuracy: 0.6810 - val_loss: 0.7633 - val_accuracy: 0.7710\n",
      "Epoch 127/200\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.9656 - accuracy: 0.6794\n",
      "Epoch 00127: val_loss did not improve from 0.73796\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9633 - accuracy: 0.6802 - val_loss: 0.7648 - val_accuracy: 0.7630\n",
      "Epoch 128/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9645 - accuracy: 0.6748\n",
      "Epoch 00128: val_loss did not improve from 0.73796\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9650 - accuracy: 0.6749 - val_loss: 0.7444 - val_accuracy: 0.7716\n",
      "Epoch 129/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.9402 - accuracy: 0.6863\n",
      "Epoch 00129: val_loss did not improve from 0.73796\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9386 - accuracy: 0.6866 - val_loss: 0.7662 - val_accuracy: 0.7728\n",
      "Epoch 130/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9479 - accuracy: 0.6869\n",
      "Epoch 00130: val_loss did not improve from 0.73796\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9477 - accuracy: 0.6869 - val_loss: 0.7609 - val_accuracy: 0.7624\n",
      "Epoch 131/200\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.9359 - accuracy: 0.6871 ETA: 0s - loss: 0.9458 - accura\n",
      "Epoch 00131: val_loss did not improve from 0.73796\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9363 - accuracy: 0.6870 - val_loss: 0.7467 - val_accuracy: 0.7710\n",
      "Epoch 132/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9303 - accuracy: 0.6828\n",
      "Epoch 00132: val_loss did not improve from 0.73796\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9302 - accuracy: 0.6826 - val_loss: 0.7477 - val_accuracy: 0.7768\n",
      "Epoch 133/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9486 - accuracy: 0.6807\n",
      "Epoch 00133: val_loss did not improve from 0.73796\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9500 - accuracy: 0.6802 - val_loss: 0.7649 - val_accuracy: 0.7544\n",
      "Epoch 134/200\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 0.9266 - accuracy: 0.6905\n",
      "Epoch 00134: val_loss did not improve from 0.73796\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9283 - accuracy: 0.6889 - val_loss: 0.7445 - val_accuracy: 0.7739\n",
      "Epoch 135/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208/219 [===========================>..] - ETA: 0s - loss: 0.9325 - accuracy: 0.6849\n",
      "Epoch 00135: val_loss improved from 0.73796 to 0.73648, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9329 - accuracy: 0.6852 - val_loss: 0.7365 - val_accuracy: 0.7762\n",
      "Epoch 136/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9368 - accuracy: 0.6843\n",
      "Epoch 00136: val_loss did not improve from 0.73648\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9362 - accuracy: 0.6842 - val_loss: 0.7414 - val_accuracy: 0.7687\n",
      "Epoch 137/200\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.9460 - accuracy: 0.6815\n",
      "Epoch 00137: val_loss did not improve from 0.73648\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9460 - accuracy: 0.6815 - val_loss: 0.7459 - val_accuracy: 0.7785\n",
      "Epoch 138/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9320 - accuracy: 0.6855 ETA: 0s - loss: 0.9598 - accu\n",
      "Epoch 00138: val_loss improved from 0.73648 to 0.73109, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9316 - accuracy: 0.6856 - val_loss: 0.7311 - val_accuracy: 0.7756\n",
      "Epoch 139/200\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.9269 - accuracy: 0.6857\n",
      "Epoch 00139: val_loss did not improve from 0.73109\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9251 - accuracy: 0.6872 - val_loss: 0.7451 - val_accuracy: 0.7716\n",
      "Epoch 140/200\n",
      "202/219 [==========================>...] - ETA: 0s - loss: 0.9320 - accuracy: 0.6898\n",
      "Epoch 00140: val_loss improved from 0.73109 to 0.72363, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.9313 - accuracy: 0.6879 - val_loss: 0.7236 - val_accuracy: 0.7848\n",
      "Epoch 141/200\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 0.9261 - accuracy: 0.6897\n",
      "Epoch 00141: val_loss did not improve from 0.72363\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9281 - accuracy: 0.6889 - val_loss: 0.7506 - val_accuracy: 0.7762\n",
      "Epoch 142/200\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.9231 - accuracy: 0.6858\n",
      "Epoch 00142: val_loss did not improve from 0.72363\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9239 - accuracy: 0.6846 - val_loss: 0.7668 - val_accuracy: 0.7676\n",
      "Epoch 143/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.9595 - accuracy: 0.6844\n",
      "Epoch 00143: val_loss did not improve from 0.72363\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9584 - accuracy: 0.6836 - val_loss: 0.7478 - val_accuracy: 0.7808\n",
      "Epoch 144/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.9281 - accuracy: 0.6902\n",
      "Epoch 00144: val_loss improved from 0.72363 to 0.71856, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9246 - accuracy: 0.6911 - val_loss: 0.7186 - val_accuracy: 0.7802\n",
      "Epoch 145/200\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.9452 - accuracy: 0.6922\n",
      "Epoch 00145: val_loss did not improve from 0.71856\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9470 - accuracy: 0.6903 - val_loss: 0.7533 - val_accuracy: 0.7836\n",
      "Epoch 146/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9135 - accuracy: 0.6902\n",
      "Epoch 00146: val_loss did not improve from 0.71856\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9112 - accuracy: 0.6912 - val_loss: 0.7315 - val_accuracy: 0.7796\n",
      "Epoch 147/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9209 - accuracy: 0.6950\n",
      "Epoch 00147: val_loss did not improve from 0.71856\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9209 - accuracy: 0.6945 - val_loss: 0.7420 - val_accuracy: 0.7699\n",
      "Epoch 148/200\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.9296 - accuracy: 0.6832\n",
      "Epoch 00148: val_loss did not improve from 0.71856\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9296 - accuracy: 0.6832 - val_loss: 0.7362 - val_accuracy: 0.7796\n",
      "Epoch 149/200\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8756 - accuracy: 0.7059\n",
      "Epoch 00149: val_loss did not improve from 0.71856\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8756 - accuracy: 0.7059 - val_loss: 0.7378 - val_accuracy: 0.7693\n",
      "Epoch 150/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9405 - accuracy: 0.6904\n",
      "Epoch 00150: val_loss did not improve from 0.71856\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9404 - accuracy: 0.6902 - val_loss: 0.7696 - val_accuracy: 0.7682\n",
      "Epoch 151/200\n",
      "204/219 [==========================>...] - ETA: 0s - loss: 0.9317 - accuracy: 0.6867\n",
      "Epoch 00151: val_loss did not improve from 0.71856\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9330 - accuracy: 0.6882 - val_loss: 0.7408 - val_accuracy: 0.7699\n",
      "Epoch 152/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.9234 - accuracy: 0.6915\n",
      "Epoch 00152: val_loss did not improve from 0.71856\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9234 - accuracy: 0.6898 - val_loss: 0.7218 - val_accuracy: 0.7831\n",
      "Epoch 153/200\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.9232 - accuracy: 0.6893\n",
      "Epoch 00153: val_loss did not improve from 0.71856\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9201 - accuracy: 0.6898 - val_loss: 0.7290 - val_accuracy: 0.7756\n",
      "Epoch 154/200\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.9150 - accuracy: 0.7016\n",
      "Epoch 00154: val_loss did not improve from 0.71856\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9173 - accuracy: 0.7005 - val_loss: 0.7337 - val_accuracy: 0.7682\n",
      "Epoch 155/200\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.9010 - accuracy: 0.7005 ETA: 0s - loss: 0.9040 - accuracy: \n",
      "Epoch 00155: val_loss improved from 0.71856 to 0.71038, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9021 - accuracy: 0.6998 - val_loss: 0.7104 - val_accuracy: 0.7859\n",
      "Epoch 156/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9175 - accuracy: 0.6849\n",
      "Epoch 00156: val_loss did not improve from 0.71038\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9181 - accuracy: 0.6849 - val_loss: 0.7195 - val_accuracy: 0.7710\n",
      "Epoch 157/200\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.9292 - accuracy: 0.6890\n",
      "Epoch 00157: val_loss did not improve from 0.71038\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9325 - accuracy: 0.6882 - val_loss: 0.7327 - val_accuracy: 0.7733\n",
      "Epoch 158/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9486 - accuracy: 0.6881\n",
      "Epoch 00158: val_loss did not improve from 0.71038\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9489 - accuracy: 0.6879 - val_loss: 0.7245 - val_accuracy: 0.7813\n",
      "Epoch 159/200\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.9082 - accuracy: 0.6946\n",
      "Epoch 00159: val_loss did not improve from 0.71038\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9095 - accuracy: 0.6941 - val_loss: 0.7243 - val_accuracy: 0.7848\n",
      "Epoch 160/200\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.9220 - accuracy: 0.6860\n",
      "Epoch 00160: val_loss did not improve from 0.71038\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9165 - accuracy: 0.6870 - val_loss: 0.7483 - val_accuracy: 0.7687\n",
      "Epoch 161/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.8941 - accuracy: 0.6975\n",
      "Epoch 00161: val_loss did not improve from 0.71038\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8977 - accuracy: 0.6972 - val_loss: 0.7287 - val_accuracy: 0.7745\n",
      "Epoch 162/200\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.9006 - accuracy: 0.6982\n",
      "Epoch 00162: val_loss improved from 0.71038 to 0.70097, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8991 - accuracy: 0.6976 - val_loss: 0.7010 - val_accuracy: 0.7813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9349 - accuracy: 0.6887\n",
      "Epoch 00163: val_loss did not improve from 0.70097\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9335 - accuracy: 0.6890 - val_loss: 0.7204 - val_accuracy: 0.7808\n",
      "Epoch 164/200\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.9172 - accuracy: 0.6991\n",
      "Epoch 00164: val_loss did not improve from 0.70097\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9161 - accuracy: 0.6986 - val_loss: 0.7215 - val_accuracy: 0.7911\n",
      "Epoch 165/200\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.9159 - accuracy: 0.6974\n",
      "Epoch 00165: val_loss did not improve from 0.70097\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9205 - accuracy: 0.6953 - val_loss: 0.7265 - val_accuracy: 0.7825\n",
      "Epoch 166/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9402 - accuracy: 0.6822\n",
      "Epoch 00166: val_loss did not improve from 0.70097\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9402 - accuracy: 0.6823 - val_loss: 0.7180 - val_accuracy: 0.7808\n",
      "Epoch 167/200\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.9011 - accuracy: 0.6981\n",
      "Epoch 00167: val_loss did not improve from 0.70097\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9011 - accuracy: 0.6981 - val_loss: 0.7163 - val_accuracy: 0.7882\n",
      "Epoch 168/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8984 - accuracy: 0.6961\n",
      "Epoch 00168: val_loss did not improve from 0.70097\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8978 - accuracy: 0.6962 - val_loss: 0.7202 - val_accuracy: 0.7836\n",
      "Epoch 169/200\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 0.8969 - accuracy: 0.6982\n",
      "Epoch 00169: val_loss improved from 0.70097 to 0.69996, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8977 - accuracy: 0.6982 - val_loss: 0.7000 - val_accuracy: 0.7956\n",
      "Epoch 170/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.9288 - accuracy: 0.6882\n",
      "Epoch 00170: val_loss did not improve from 0.69996\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9287 - accuracy: 0.6878 - val_loss: 0.7393 - val_accuracy: 0.7790\n",
      "Epoch 171/200\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 0.8988 - accuracy: 0.6965\n",
      "Epoch 00171: val_loss did not improve from 0.69996\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8988 - accuracy: 0.6962 - val_loss: 0.7094 - val_accuracy: 0.7808\n",
      "Epoch 172/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9092 - accuracy: 0.6984\n",
      "Epoch 00172: val_loss did not improve from 0.69996\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9095 - accuracy: 0.6984 - val_loss: 0.7077 - val_accuracy: 0.7813\n",
      "Epoch 173/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9047 - accuracy: 0.6966\n",
      "Epoch 00173: val_loss did not improve from 0.69996\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9047 - accuracy: 0.6974 - val_loss: 0.7030 - val_accuracy: 0.7836\n",
      "Epoch 174/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9053 - accuracy: 0.7014\n",
      "Epoch 00174: val_loss did not improve from 0.69996\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9056 - accuracy: 0.7014 - val_loss: 0.7157 - val_accuracy: 0.7894\n",
      "Epoch 175/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.8983 - accuracy: 0.6954\n",
      "Epoch 00175: val_loss did not improve from 0.69996\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8985 - accuracy: 0.6959 - val_loss: 0.7032 - val_accuracy: 0.7934\n",
      "Epoch 176/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9167 - accuracy: 0.6895\n",
      "Epoch 00176: val_loss did not improve from 0.69996\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9168 - accuracy: 0.6895 - val_loss: 0.7045 - val_accuracy: 0.7739\n",
      "Epoch 177/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8969 - accuracy: 0.7023\n",
      "Epoch 00177: val_loss did not improve from 0.69996\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8964 - accuracy: 0.7024 - val_loss: 0.7302 - val_accuracy: 0.7739\n",
      "Epoch 178/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9340 - accuracy: 0.6858\n",
      "Epoch 00178: val_loss did not improve from 0.69996\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9337 - accuracy: 0.6855 - val_loss: 0.7274 - val_accuracy: 0.7750\n",
      "Epoch 179/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8940 - accuracy: 0.6948\n",
      "Epoch 00179: val_loss did not improve from 0.69996\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8932 - accuracy: 0.6951 - val_loss: 0.7123 - val_accuracy: 0.7750\n",
      "Epoch 180/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.8921 - accuracy: 0.7016\n",
      "Epoch 00180: val_loss did not improve from 0.69996\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8927 - accuracy: 0.7016 - val_loss: 0.7007 - val_accuracy: 0.7894\n",
      "Epoch 181/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9170 - accuracy: 0.6989\n",
      "Epoch 00181: val_loss did not improve from 0.69996\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9167 - accuracy: 0.6986 - val_loss: 0.7094 - val_accuracy: 0.7802\n",
      "Epoch 182/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9363 - accuracy: 0.6881\n",
      "Epoch 00182: val_loss did not improve from 0.69996\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9359 - accuracy: 0.6882 - val_loss: 0.7096 - val_accuracy: 0.7876\n",
      "Epoch 183/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.9020 - accuracy: 0.6957\n",
      "Epoch 00183: val_loss did not improve from 0.69996\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9042 - accuracy: 0.6948 - val_loss: 0.7038 - val_accuracy: 0.7922\n",
      "Epoch 184/200\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8860 - accuracy: 0.7057\n",
      "Epoch 00184: val_loss did not improve from 0.69996\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8860 - accuracy: 0.7057 - val_loss: 0.7139 - val_accuracy: 0.7831\n",
      "Epoch 185/200\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 0.8937 - accuracy: 0.6968\n",
      "Epoch 00185: val_loss did not improve from 0.69996\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8973 - accuracy: 0.6949 - val_loss: 0.7215 - val_accuracy: 0.7773\n",
      "Epoch 186/200\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 0.8992 - accuracy: 0.7016\n",
      "Epoch 00186: val_loss did not improve from 0.69996\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8958 - accuracy: 0.7002 - val_loss: 0.7115 - val_accuracy: 0.7905\n",
      "Epoch 187/200\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.8987 - accuracy: 0.6978\n",
      "Epoch 00187: val_loss did not improve from 0.69996\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8985 - accuracy: 0.6986 - val_loss: 0.7184 - val_accuracy: 0.7939\n",
      "Epoch 188/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.9019 - accuracy: 0.6999\n",
      "Epoch 00188: val_loss improved from 0.69996 to 0.69326, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9021 - accuracy: 0.7004 - val_loss: 0.6933 - val_accuracy: 0.7968\n",
      "Epoch 189/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8853 - accuracy: 0.7051\n",
      "Epoch 00189: val_loss improved from 0.69326 to 0.68712, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8856 - accuracy: 0.7049 - val_loss: 0.6871 - val_accuracy: 0.7985\n",
      "Epoch 190/200\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.8966 - accuracy: 0.7031\n",
      "Epoch 00190: val_loss did not improve from 0.68712\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8987 - accuracy: 0.7026 - val_loss: 0.6900 - val_accuracy: 0.7911\n",
      "Epoch 191/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8969 - accuracy: 0.7071\n",
      "Epoch 00191: val_loss did not improve from 0.68712\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8983 - accuracy: 0.7069 - val_loss: 0.6917 - val_accuracy: 0.7848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/200\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.9038 - accuracy: 0.6953\n",
      "Epoch 00192: val_loss did not improve from 0.68712\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9038 - accuracy: 0.6953 - val_loss: 0.7002 - val_accuracy: 0.7916\n",
      "Epoch 193/200\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.8976 - accuracy: 0.7012\n",
      "Epoch 00193: val_loss did not improve from 0.68712\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8976 - accuracy: 0.7012 - val_loss: 0.6964 - val_accuracy: 0.7916\n",
      "Epoch 194/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8939 - accuracy: 0.7046\n",
      "Epoch 00194: val_loss improved from 0.68712 to 0.68285, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8941 - accuracy: 0.7047 - val_loss: 0.6829 - val_accuracy: 0.7859\n",
      "Epoch 195/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8737 - accuracy: 0.7004 ETA: 0s - loss: 0.8611 - accura\n",
      "Epoch 00195: val_loss did not improve from 0.68285\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8734 - accuracy: 0.7005 - val_loss: 0.6967 - val_accuracy: 0.7997\n",
      "Epoch 196/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.9037 - accuracy: 0.7027\n",
      "Epoch 00196: val_loss did not improve from 0.68285\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9036 - accuracy: 0.7028 - val_loss: 0.7057 - val_accuracy: 0.7808\n",
      "Epoch 197/200\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 0.8989 - accuracy: 0.7079\n",
      "Epoch 00197: val_loss did not improve from 0.68285\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8996 - accuracy: 0.7075 - val_loss: 0.7089 - val_accuracy: 0.7888\n",
      "Epoch 198/200\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.8994 - accuracy: 0.7008\n",
      "Epoch 00198: val_loss did not improve from 0.68285\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.9026 - accuracy: 0.6999 - val_loss: 0.7121 - val_accuracy: 0.7911\n",
      "Epoch 199/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8775 - accuracy: 0.7107\n",
      "Epoch 00199: val_loss improved from 0.68285 to 0.68026, saving model to saved_models/audio_classification.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8775 - accuracy: 0.7107 - val_loss: 0.6803 - val_accuracy: 0.7974\n",
      "Epoch 200/200\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.8798 - accuracy: 0.7020\n",
      "Epoch 00200: val_loss did not improve from 0.68026\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.8798 - accuracy: 0.7018 - val_loss: 0.6869 - val_accuracy: 0.7939\n",
      "Training completed in time:  0:02:25.857856\n"
     ]
    }
   ],
   "source": [
    "## Trianing my model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 200\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6c0c983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7939324378967285\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225a5ca9",
   "metadata": {},
   "source": [
    "# Testing Some Test Audio Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d297de",
   "metadata": {},
   "source": [
    "Steps\n",
    "\n",
    "Preprocess the new audio data\n",
    "\n",
    "predict the classes\n",
    "\n",
    "Invere transform your Predicted Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68a396d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.01122711e+02  1.53056015e+02  9.15836525e+00 -1.04600391e+01\n",
      " -1.64918995e+01  3.58699512e+00 -1.36686192e+01 -8.68370914e+00\n",
      " -4.45985365e+00 -7.58018064e+00 -8.65039289e-01 -2.98663425e+00\n",
      "  4.75616646e+00  8.72414207e+00  9.36257172e+00  1.46945305e+01\n",
      "  5.44877768e+00 -8.84514973e-02  7.87338853e-01 -3.53762913e+00\n",
      "  7.84663390e-03 -2.13275695e+00 -4.25562906e+00 -4.67474490e-01\n",
      " -4.37626481e-01  2.55075169e+00  2.95378089e+00  3.44757819e+00\n",
      "  4.33649969e+00  3.61894798e+00  3.66083050e+00  5.44085860e-01\n",
      "  1.18284881e+00  1.53016174e+00  8.98930550e-01 -5.55400014e-01\n",
      " -2.51318526e+00 -1.23046386e+00 -1.45281053e+00  4.28475708e-01]\n",
      "[[-4.01122711e+02  1.53056015e+02  9.15836525e+00 -1.04600391e+01\n",
      "  -1.64918995e+01  3.58699512e+00 -1.36686192e+01 -8.68370914e+00\n",
      "  -4.45985365e+00 -7.58018064e+00 -8.65039289e-01 -2.98663425e+00\n",
      "   4.75616646e+00  8.72414207e+00  9.36257172e+00  1.46945305e+01\n",
      "   5.44877768e+00 -8.84514973e-02  7.87338853e-01 -3.53762913e+00\n",
      "   7.84663390e-03 -2.13275695e+00 -4.25562906e+00 -4.67474490e-01\n",
      "  -4.37626481e-01  2.55075169e+00  2.95378089e+00  3.44757819e+00\n",
      "   4.33649969e+00  3.61894798e+00  3.66083050e+00  5.44085860e-01\n",
      "   1.18284881e+00  1.53016174e+00  8.98930550e-01 -5.55400014e-01\n",
      "  -2.51318526e+00 -1.23046386e+00 -1.45281053e+00  4.28475708e-01]]\n",
      "(1, 40)\n",
      "WARNING:tensorflow:From <ipython-input-25-4c72c7f8631a>:10: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "[3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['dog_bark'], dtype='<U16')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename=\"UrbanSound8K/dog_bark.wav\"\n",
    "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "\n",
    "print(mfccs_scaled_features)\n",
    "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
    "print(mfccs_scaled_features)\n",
    "print(mfccs_scaled_features.shape)\n",
    "predicted_label=model.predict_classes(mfccs_scaled_features)\n",
    "print(predicted_label)# we get 3 label but we dont no which class it belong\n",
    "prediction_class = labelencoder.inverse_transform(predicted_label) # we use inverse_transform to get the class name\n",
    "prediction_class\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
